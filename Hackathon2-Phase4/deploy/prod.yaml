# Production Deployment Configuration for AI Todo Chatbot

apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-todo-chatbot-backend
  namespace: production
  labels:
    app: ai-todo-chatbot
    tier: backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ai-todo-chatbot
      tier: backend
  template:
    metadata:
      labels:
        app: ai-todo-chatbot
        tier: backend
    spec:
      containers:
      - name: backend
        image: ai-todo-chatbot:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secrets
              key: url
        - name: GEMINI_API_KEY
          valueFrom:
            secretKeyRef:
              name: llm-secrets
              key: gemini-api-key
        - name: BETTER_AUTH_SECRET
          valueFrom:
            secretKeyRef:
              name: auth-secrets
              key: secret
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: ai-todo-chatbot-service
  namespace: production
spec:
  selector:
    app: ai-todo-chatbot
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: ClusterIP

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ai-todo-chatbot-ingress
  namespace: production
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - api.ai-todo-chatbot.example.com
    secretName: ai-todo-chatbot-tls
  rules:
  - host: api.ai-todo-chatbot.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: ai-todo-chatbot-service
            port:
              number: 80

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ai-todo-chatbot-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ai-todo-chatbot-backend
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80

---
# Frontend Configuration
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-todo-chatbot-frontend
  namespace: production
  labels:
    app: ai-todo-chatbot
    tier: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ai-todo-chatbot
      tier: frontend
  template:
    metadata:
      labels:
        app: ai-todo-chatbot
        tier: frontend
    spec:
      containers:
      - name: frontend
        image: ai-todo-chatbot-frontend:latest
        ports:
        - containerPort: 3000
        env:
        - name: NEXT_PUBLIC_API_URL
          value: "https://api.ai-todo-chatbot.example.com"
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-todo-chatbot-config
  namespace: production
data:
  # Application configuration
  LOG_LEVEL: "INFO"
  MAX_CONCURRENT_USERS: "100"
  RATE_LIMIT_REQUESTS_PER_MINUTE: "60"
  SESSION_TIMEOUT_MINUTES: "60"